{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-02 04:45:04 [info   ] Parsing 1 documents            [agentic_doc.parse] (parse.py:243)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing documents:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-02 04:45:04 [info   ] Splitting PDF: 'pdf_samples\\John Feng Resume Hard Tech 2025-05-25.pdf' into 0 parts under 'C:\\Users\\johnk\\AppData\\Local\\Temp\\tmph2j_b5i9' [agentic_doc.utils] (utils.py:193)\n",
      "2025-06-02 04:45:04 [info   ] Created C:\\Users\\johnk\\AppData\\Local\\Temp\\tmph2j_b5i9\\John Feng Resume Hard Tech 2025-05-25_1.pdf [agentic_doc.utils] (utils.py:209)\n",
      "2025-06-02 04:45:04 [info   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing document parts from 'John Feng Resume Hard Tech 2025-05-25.pdf':   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start parsing document part: 'File name: John Feng Resume Hard Tech 2025-05-25_1.pdf\tPage: [0:0]' [agentic_doc.parse] (parse.py:442)\n",
      "HTTP Request: POST https://api.va.landing.ai/v1/tools/agentic-document-analysis \"HTTP/1.1 200 OK\" (_client.py:1025)\n",
      "2025-06-02 04:45:20 [info   ] Time taken to successfully parse a document chunk: 15.31 seconds [agentic_doc.parse] (parse.py:526)\n",
      "2025-06-02 04:45:20 [info   ] Successfully parsed document part: 'File name: John Feng Resume Hard Tech 2025-05-25_1.pdf\tPage: [0:0]' [agentic_doc.parse] (parse.py:448)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Parsing document parts from 'John Feng Resume Hard Tech 2025-05-25.pdf': 100%|██████████| 1/1 [00:15<00:00, 15.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-02 04:45:20 [info   ] Saved the parsed result to 'app_storage\\parsed_docs_save\\John Feng Resume Hard Tech 2025-05-25_20250601_214520.json' [agentic_doc.parse] (parse.py:323)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing documents: 100%|██████████| 1/1 [00:15<00:00, 15.48s/it]\n"
     ]
    }
   ],
   "source": [
    "from agentic_doc.parse import parse\n",
    "from agentic_doc.connectors import LocalConnectorConfig\n",
    "from pathlib import Path\n",
    "\n",
    "config = LocalConnectorConfig()\n",
    "\n",
    "\n",
    "RESULT_SAVE_DIR = Path(\"app_storage/parsed_docs_save\")\n",
    "doc_path = \"pdf_samples/John Feng Resume Hard Tech 2025-05-25.pdf\"\n",
    "# doc_path = \"pdf_samples/ignore/Rejhon_2017_Semicond_Sci_Technol_32_085007.pdf\"\n",
    "# Parse all supported documents in a directory\n",
    "results = parse(config, connector_path=doc_path,\n",
    "                result_save_dir=RESULT_SAVE_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'doc_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpickle\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Save the parsed results to a pickle file\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m pickle_file_name = \u001b[43mdoc_path\u001b[49m.split(\u001b[33m\"\u001b[39m\u001b[33m/\u001b[39m\u001b[33m\"\u001b[39m)[-\u001b[32m1\u001b[39m].split(\u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m)[\u001b[32m0\u001b[39m] + \u001b[33m\"\u001b[39m\u001b[33m.pkl\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(pickle_file_name, \u001b[33m'\u001b[39m\u001b[33mwb\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m      6\u001b[39m     pickle.dump(results, f)\n",
      "\u001b[31mNameError\u001b[39m: name 'doc_path' is not defined"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the parsed results to a pickle file\n",
    "pickle_file_name = doc_path.split(\"/\")[-1].split(\".\")[0] + \".pkl\"\n",
    "with open(pickle_file_name, 'wb') as f:\n",
    "    pickle.dump(results, f)\n",
    "\n",
    "print(f\"Results saved to {pickle_file_name}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start with loaded pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-02 04:23:17 [info   ] Settings loaded: {\n",
      "  \"endpoint_host\": \"https://api.va.landing.ai\",\n",
      "  \"vision_agent_api_key\": \"amU5M[REDACTED]\",\n",
      "  \"batch_size\": 4,\n",
      "  \"max_workers\": 5,\n",
      "  \"max_retries\": 80,\n",
      "  \"max_retry_wait_time\": 30,\n",
      "  \"retry_logging_style\": \"log_msg\",\n",
      "  \"pdf_to_image_dpi\": 96,\n",
      "  \"split_size\": 10\n",
      "} [agentic_doc.config] (config.py:84)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from agentic_doc.utils import viz_parsed_document\n",
    "from agentic_doc.config import VisualizationConfig\n",
    "from agentic_doc.common import ChunkType\n",
    "\n",
    "def create_visualizations(parsed_results, \n",
    "                          doc_path, \n",
    "                          output_dir,\n",
    "                          text_color=(0, 0, 255),\n",
    "                          table_color=(0, 255, 0),\n",
    "                          figure_color=(255, 0, 0),\n",
    "                          marginalia_color=(0, 255, 255)):\n",
    "\n",
    "    # Check if output directory exists, if not create it\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    viz_config = VisualizationConfig(\n",
    "        thickness=1,  # Thicker bounding boxes\n",
    "        text_bg_opacity=0.5,  # More opaque text background\n",
    "        font_scale=0.7,  # Larger text\n",
    "        # Custom colors for different chunk types\n",
    "        color_map={\n",
    "            ChunkType.text: text_color,  # Red for tables\n",
    "            ChunkType.table: table_color,  # Green for tables\n",
    "            ChunkType.figure: figure_color,  # Blue for text\n",
    "            ChunkType.marginalia: marginalia_color\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    for parsed_doc in parsed_results:\n",
    "        images = viz_parsed_document(\n",
    "            doc_path,\n",
    "            parsed_doc,\n",
    "            output_dir=output_dir,\n",
    "            viz_config=viz_config\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results loaded from parsed_results.pkl\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "pkl_path = \"app_storage/parsed_docs_pkl/John Feng Resume Hard Tech 2025-05-25.pkl\"\n",
    "# Load the parsed results from the pickle file\n",
    "with open(pkl_path, 'rb') as f:\n",
    "    loaded_parsed_results = pickle.load(f)\n",
    "\n",
    "print(\"Results loaded from parsed_results.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- MARKDOWN ----\n",
      "John Feng <!-- text, from page 0 (l=0.404,t=0.043,r=0.594,b=0.078), with ID 8bc97eaf-473c-41bb-95eb-f4ac74a4425e -->\n",
      "\n",
      "Victoria, BC, Canada • johnfengphd@gmail.com • +1 (647) 716-7981  \n",
      "LinkedIn: https://www.linkedin.com/in/john-feng-5735321b8/ <!-- text, from page 0 (l=0.215,t=0.077,r=0.782,b=0.115), with ID e1f20701-a95e-4be4-8b01-bcff0a77c787 -->\n",
      "\n",
      "**Skills:** CAD (Autodesk Inventor, Solidworks), 3D printing, Ultrafast Lasers, Ultra-high vacuum systems, High voltage systems, Writing technical reports, Public Speaking, Data Science, Machine Learning <!-- text, from page 0 (l=0.048,t=0.116,r=0.901,b=0.153), with ID e0f9cfd9-325d-4601-9851-46907df169c5 -->\n",
      "\n",
      "**Education**\n",
      "\n",
      "BSc Physics specialist, Human Biology major - University of Toronto  \n",
      "MSc in Physics - University of Toronto  \n",
      "PhD in Physics - University of Toronto\n",
      "\n",
      "- [Van Kronecker Teaching Assistant Award](https://www.example.com) (2021)\n",
      "- [3-minute thesis University of Toronto finalist](https://www.example.com) (2017, 2018)\n",
      "\n",
      "completed Apr 2013  \n",
      "completed Aug 2014  \n",
      "completed Dec 2022 <!-- text, from page 0 (l=0.051,t=0.161,r=0.924,b=0.263), with ID fcaac556-b566-4f89-9b94-b4ef2b8bc586 -->\n",
      "\n",
      "- • Build and refine physics-based models of semiconductor materials, studying carrier dynamics, space charge effects, and material defects - work with a small agile team of engineers and scientists.\n",
      "- • Develop and execute test methods to characterize semiconductor devices via electro-optic properties, analyzing results to improve device performance.\n",
      "- • Root cause analysis of our persistent performance issues in our detector product\n",
      "- • Hands on experience in free-space optical alignment, optomechanics, and optical components.\n",
      "- • Software engineering: Code Python scripts for automated data acquisition and analysis, maintain proper version control and documentation with GitHub. Hand-over packaged software for other users.\n",
      "- • Write reports and present project plans, proposals, and results for technical and business audiences.\n",
      "- • Project Management: Communicate with vendors, understanding technical details of hardware before purchasing.\n",
      "- • Create detailed parts lists for project proposals. Assess risk of failure in projects.\n",
      "- • Proficient in CAD software such as SolidWorks, Onshape - design custom hardware for lab work.\n",
      "- • Refine apparatus to pass Gauge Repeatability and Reproducibility standards.\n",
      "- • Data Science: Very proficient in Python (Pandas, Matplotlib, Plotly, Streamlit, Numpy, Scipy), JMP Statistical Software, COMSOL. Familiar with MATLAB and Monte-Carlo simulations. <!-- text, from page 0 (l=0.050,t=0.277,r=0.946,b=0.524), with ID 51884144-2e5d-4049-9e93-33bdb11c6122 -->\n",
      "\n",
      "- • College admissions chatbot helper: Scrape college websites for admissions details and program specific information using Python Scrapy\n",
      "- • Created automated chatbot with Python backend for answering international college admission query\n",
      "- • Applied AI Retrieval Augmented Generation method in backend\n",
      "- • Work in a small agile team of front-end developers and project manager\n",
      "- • Contribute to free open-source community-driven project slack agent (Sherpa AI) for querying slack conversation history and database. <!-- text, from page 0 (l=0.051,t=0.527,r=0.943,b=0.657), with ID 1532a410-58c5-4a49-ab3a-e3afb0fdab1d -->\n",
      "\n",
      "Research Assistant at University of Toronto                                            Sept 2016 - Dec 2022\n",
      "My primary Ph.D. research project was the design and construction of a novel >100kV electron accelerator with semiconductor photocathode source - Ultrafast Electron Diffractometer. This is a complex apparatus built for the purpose of probing matter at the atomic scale in ultrafast timescales. I led the planning, design, construction, and other technical work throughout this project. [Link to PhD Thesis] <!-- text, from page 0 (l=0.051,t=0.660,r=0.940,b=0.748), with ID 909e434b-af81-47d1-b307-6d28d00843dc -->\n",
      "\n",
      "- • Plan, manage, build full lifecycle of complex engineering project ($300k total cost) from initial conception to hardware prototype\n",
      "- • Developed Python-based software for instrument control and data processing\n",
      "- • Hands-on experience with various lab equipment: electronics, lasers, nonlinear optics, ultra-high vacuum\n",
      "- • Modeled accelerated electron pulse dynamics with C++ based particle simulation software\n",
      "- • Experience in vacuum engineering, high voltage engineering (>100kV), high voltage conditioning, CAD design, programming for instrument controls, data analysis, ultrafast lasers, and basic electronics\n",
      "- • Coordinate the design, manufacture and procurement of specialized high voltage and ultra high vacuum components from various vendors and cross-functional teams world-wide\n",
      "- • Writing comprehensive reports, creating conference posters, and presentations about my project for a technical audience and lay audience <!-- text, from page 0 (l=0.080,t=0.757,r=0.928,b=0.922), with ID 500a90b7-1224-4838-903e-4210ef95e9d6 -->\n",
      "---- DOC TYPE ----\n",
      "pdf\n",
      "\n",
      "--------------------------------\n",
      "\n",
      "++ CHUNK 0:\n",
      "text='John Feng' grounding=[ChunkGrounding(page=0, box=ChunkGroundingBox(l=0.40431854128837585, t=0.042796455323696136, r=0.5939605832099915, b=0.07849801331758499), image_path=None)] chunk_type=<ChunkType.text: 'text'> chunk_id='8bc97eaf-473c-41bb-95eb-f4ac74a4425e'\n",
      "++ CHUNK 1:\n",
      "text='Victoria, BC, Canada • johnfengphd@gmail.com • +1 (647) 716-7981  \\nLinkedIn: https://www.linkedin.com/in/john-feng-5735321b8/' grounding=[ChunkGrounding(page=0, box=ChunkGroundingBox(l=0.2153419554233551, t=0.07690517604351044, r=0.7817039489746094, b=0.11479306221008301), image_path=None)] chunk_type=<ChunkType.text: 'text'> chunk_id='e1f20701-a95e-4be4-8b01-bcff0a77c787'\n",
      "++ CHUNK 2:\n",
      "text='**Skills:** CAD (Autodesk Inventor, Solidworks), 3D printing, Ultrafast Lasers, Ultra-high vacuum systems, High voltage systems, Writing technical reports, Public Speaking, Data Science, Machine Learning' grounding=[ChunkGrounding(page=0, box=ChunkGroundingBox(l=0.04770520329475403, t=0.11559978127479553, r=0.9006589651107788, b=0.15263673663139343), image_path=None)] chunk_type=<ChunkType.text: 'text'> chunk_id='e0f9cfd9-325d-4601-9851-46907df169c5'\n",
      "++ CHUNK 3:\n",
      "text='**Education**\\n\\nBSc Physics specialist, Human Biology major - University of Toronto  \\nMSc in Physics - University of Toronto  \\nPhD in Physics - University of Toronto\\n\\n- [Van Kronecker Teaching Assistant Award](https://www.example.com) (2021)\\n- [3-minute thesis University of Toronto finalist](https://www.example.com) (2017, 2018)\\n\\ncompleted Apr 2013  \\ncompleted Aug 2014  \\ncompleted Dec 2022' grounding=[ChunkGrounding(page=0, box=ChunkGroundingBox(l=0.05079150199890137, t=0.16065055131912231, r=0.9238680005073547, b=0.26325535774230957), image_path=None)] chunk_type=<ChunkType.text: 'text'> chunk_id='fcaac556-b566-4f89-9b94-b4ef2b8bc586'\n",
      "++ CHUNK 4:\n",
      "text='- • Build and refine physics-based models of semiconductor materials, studying carrier dynamics, space charge effects, and material defects - work with a small agile team of engineers and scientists.\\n- • Develop and execute test methods to characterize semiconductor devices via electro-optic properties, analyzing results to improve device performance.\\n- • Root cause analysis of our persistent performance issues in our detector product\\n- • Hands on experience in free-space optical alignment, optomechanics, and optical components.\\n- • Software engineering: Code Python scripts for automated data acquisition and analysis, maintain proper version control and documentation with GitHub. Hand-over packaged software for other users.\\n- • Write reports and present project plans, proposals, and results for technical and business audiences.\\n- • Project Management: Communicate with vendors, understanding technical details of hardware before purchasing.\\n- • Create detailed parts lists for project proposals. Assess risk of failure in projects.\\n- • Proficient in CAD software such as SolidWorks, Onshape - design custom hardware for lab work.\\n- • Refine apparatus to pass Gauge Repeatability and Reproducibility standards.\\n- • Data Science: Very proficient in Python (Pandas, Matplotlib, Plotly, Streamlit, Numpy, Scipy), JMP Statistical Software, COMSOL. Familiar with MATLAB and Monte-Carlo simulations.' grounding=[ChunkGrounding(page=0, box=ChunkGroundingBox(l=0.04971712827682495, t=0.27692142128944397, r=0.9455770254135132, b=0.5238361358642578), image_path=None)] chunk_type=<ChunkType.text: 'text'> chunk_id='51884144-2e5d-4049-9e93-33bdb11c6122'\n",
      "++ CHUNK 5:\n",
      "text='- • College admissions chatbot helper: Scrape college websites for admissions details and program specific information using Python Scrapy\\n- • Created automated chatbot with Python backend for answering international college admission query\\n- • Applied AI Retrieval Augmented Generation method in backend\\n- • Work in a small agile team of front-end developers and project manager\\n- • Contribute to free open-source community-driven project slack agent (Sherpa AI) for querying slack conversation history and database.' grounding=[ChunkGrounding(page=0, box=ChunkGroundingBox(l=0.051045000553131104, t=0.5273938179016113, r=0.9432618618011475, b=0.6565538644790649), image_path=None)] chunk_type=<ChunkType.text: 'text'> chunk_id='1532a410-58c5-4a49-ab3a-e3afb0fdab1d'\n",
      "++ CHUNK 6:\n",
      "text='Research Assistant at University of Toronto                                            Sept 2016 - Dec 2022\\nMy primary Ph.D. research project was the design and construction of a novel >100kV electron accelerator with semiconductor photocathode source - Ultrafast Electron Diffractometer. This is a complex apparatus built for the purpose of probing matter at the atomic scale in ultrafast timescales. I led the planning, design, construction, and other technical work throughout this project. [Link to PhD Thesis]' grounding=[ChunkGrounding(page=0, box=ChunkGroundingBox(l=0.05114099383354187, t=0.6601967811584473, r=0.9403232336044312, b=0.7475917339324951), image_path=None)] chunk_type=<ChunkType.text: 'text'> chunk_id='909e434b-af81-47d1-b307-6d28d00843dc'\n",
      "++ CHUNK 7:\n",
      "text='- • Plan, manage, build full lifecycle of complex engineering project ($300k total cost) from initial conception to hardware prototype\\n- • Developed Python-based software for instrument control and data processing\\n- • Hands-on experience with various lab equipment: electronics, lasers, nonlinear optics, ultra-high vacuum\\n- • Modeled accelerated electron pulse dynamics with C++ based particle simulation software\\n- • Experience in vacuum engineering, high voltage engineering (>100kV), high voltage conditioning, CAD design, programming for instrument controls, data analysis, ultrafast lasers, and basic electronics\\n- • Coordinate the design, manufacture and procurement of specialized high voltage and ultra high vacuum components from various vendors and cross-functional teams world-wide\\n- • Writing comprehensive reports, creating conference posters, and presentations about my project for a technical audience and lay audience' grounding=[ChunkGrounding(page=0, box=ChunkGroundingBox(l=0.07974934577941895, t=0.7568103671073914, r=0.9284714460372925, b=0.9215696454048157), image_path=None)] chunk_type=<ChunkType.text: 'text'> chunk_id='500a90b7-1224-4838-903e-4210ef95e9d6'\n"
     ]
    }
   ],
   "source": [
    "for parsed_result in loaded_parsed_results:\n",
    "    print(f\"---- MARKDOWN ----\")\n",
    "    print(parsed_result.markdown)\n",
    "    print(\"---- DOC TYPE ----\")\n",
    "    print(parsed_result.doc_type)\n",
    "    print(\"\\n--------------------------------\\n\")\n",
    "    for i, chunk in enumerate(parsed_result.chunks):\n",
    "        print(f\"++ CHUNK {i}:\")\n",
    "        print(chunk)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ParsedDocument' object has no attribute 'to_json'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 28\u001b[39m\n\u001b[32m     24\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m json_object\n\u001b[32m     26\u001b[39m doc_path = \u001b[33m\"\u001b[39m\u001b[33mpdf_samples/John Feng Resume Hard Tech 2025-05-25.pdf\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m json_object = \u001b[43mcreate_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloaded_parsed_results\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdoc_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 16\u001b[39m, in \u001b[36mcreate_json\u001b[39m\u001b[34m(parsed_result, doc_path)\u001b[39m\n\u001b[32m     13\u001b[39m json_file_path = os.path.join(json_dir, json_file_name)\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# Convert the parsed result to a JSON object\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m json_object = \u001b[43mparsed_result\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_json\u001b[49m()\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# Write the JSON object to the file as a string\u001b[39;00m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(json_file_path, \u001b[33m'\u001b[39m\u001b[33mw\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\johnk\\Projects-code\\LEARN\\landing-ai\\.venv\\Lib\\site-packages\\pydantic\\main.py:991\u001b[39m, in \u001b[36mBaseModel.__getattr__\u001b[39m\u001b[34m(self, item)\u001b[39m\n\u001b[32m    988\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__getattribute__\u001b[39m(item)  \u001b[38;5;66;03m# Raises AttributeError if appropriate\u001b[39;00m\n\u001b[32m    989\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    990\u001b[39m     \u001b[38;5;66;03m# this is the current error\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m991\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m object has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: 'ParsedDocument' object has no attribute 'to_json'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "def create_json(parsed_result, doc_path):\n",
    "\n",
    "    # Create a directory for JSON files\n",
    "    json_dir = \"app_storage/parsed_docs_json\"\n",
    "    if not os.path.exists(json_dir):\n",
    "        os.makedirs(json_dir)\n",
    "\n",
    "    # Create a JSON file for each parsed result\n",
    "    json_file_name = doc_path.split(\"/\")[-1].split(\".\")[0] + \".json\"\n",
    "    json_file_path = os.path.join(json_dir, json_file_name)\n",
    "\n",
    "    # Convert the parsed result to a JSON object\n",
    "    json_object = parsed_result.to_json()\n",
    "\n",
    "    # Write the JSON object to the file as a string\n",
    "    with open(json_file_path, 'w') as f:\n",
    "        f.write(json_object)\n",
    "\n",
    "    print(f\"JSON file {json_file_name} created successfully\")   \n",
    "\n",
    "    return json_object\n",
    "\n",
    "doc_path = \"pdf_samples/John Feng Resume Hard Tech 2025-05-25.pdf\"\n",
    "\n",
    "json_object = create_json(loaded_parsed_results[0], doc_path)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'doc_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# create_visualizations(results, doc_path)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m create_visualizations(loaded_parsed_results, \u001b[43mdoc_path\u001b[49m)\n",
      "\u001b[31mNameError\u001b[39m: name 'doc_path' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# create_visualizations(results, doc_path)\n",
    "create_visualizations(loaded_parsed_results, doc_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
